.onUnload<-function(libpath){
  library.dynam.unload("mypackage",libpath)
}

#'Get patterns
#'
#'Auxiliary function written in \code{R} for providing the necessary information
#'about the patterns generated by raters.This function produces the
#'input for the EM-algorithm.
#'
#'@param data \code{Matrix} or \code{data.frame} containing the ratings. The
#'cases are in the rows and the raters are in the columns. Characters in the cells
#'are supported. At least two raters are necessary.
#'@param categorical_levels \code{Vector} containing all possible categories of
#'the content analysis.
#'@return Function retuns a \code{List} with the following components:
#'\item{n}{Integer representing the number of different patterns in the data.}
#'\item{shape}{\code{Matrix} containing all unique patterns in in the data.
#'Cells of the matrix are characters.}
#'\item{frq}{\code{Vector} containing the frequencies of the patterns.}
#'\item{count}{\code{Matrix} containing the relative frequencies of the
#'categories within each pattern. The number of rows equals the number of
#'patterns. The number of columns equals the number of categories.}
#'@export
get_patterns<-function(data,categorical_levels){

  n_rater<-ncol(data)
  pattern_shape<-unique(data)
  pattern_shape<-matrix(sapply(pattern_shape,as.character),ncol=n_rater)
  pattern_id<-vector(length = nrow(data))
  for(i in 1:nrow(data)){
    pattern_id[i]<-paste0(sapply(data[i,],as.character),collapse = "")
  }

  pattern_frq<-vector(length = nrow(pattern_shape))
  for(i in 1:nrow(pattern_shape)){
    tmp<-pattern_id
    tmp<-pattern_id==paste0(pattern_shape[i,],collapse = "")
    pattern_frq[i]<-sum(tmp)
  }

  internal_count_frq<-matrix(data=NA,nrow = nrow(pattern_shape),ncol=length(categorical_levels))
  colnames(internal_count_frq)<-categorical_levels
  for (k in categorical_levels){
    tmp<-pattern_shape
    tmp<-tmp==k
    internal_count_frq[,k]<-rowSums(tmp)
  }
  internal_count_frq<-internal_count_frq/n_rater

  pattern<-NULL
  pattern["n"]<-list(nrow(pattern_shape))
  pattern["shape"]<-list(pattern_shape)
  pattern["frq"]<-list(pattern_frq)
  pattern["count"]<-list(internal_count_frq)
  return(pattern)
}

#' Computes Iota and its elements in version 2
#'
#' Computes all elements of the Iota Reliability Concept
#'
#' @param data Data for which the elements should be estimated. Data must be
#' an object of type data.frame or matrix with cases in the rows and
#' raters in the columns.
#' @param random_starts An integer for the number of random starts for the
#' EM-algorithm.
#' @param max_iterations An integer for the maximum number of iterations within
#' the EM-algorithm.
#' @param cr_rel_change Positive numeric value for defining the convergence of the
#' EM-algorithm.
#' @param step_size \code{Double} for specifying the size for increasing or
#' decreasing the probabilities during the condition stage of estimation.
#' This value should not be less than 1e-3.
#' @param b_min Value ranging between 0 and 1 determining the minimal size of
#' the categories for checking if boundary values occured. The algorithm tries
#' to select solution that are not considered to be boundary values.
#' @param trace Boolean. \code{TRUE} if information on the estimation progress
#' should be printed to the console.
#' @return Returns a \code{List} with the following three components:
#' The first component \code{estimates_categorical_level} comprises all
#' elements that describe the ratings on a categorical level. The elements are
#' sub-divided into raw estimates and chance-corrected estimates.
#' \describe{
#' \item{\code{raw_estimates}}{
#' \itemize{
#' \item{\code{alpha_reliability: }}{A vector containing the Alpha
#' Reliabilities for each category. These values represent probabilities.}
#' \item{\code{beta_reliability: }}{A vector containing the Beta Reliabilities for each
#' category. These values represent probabilities.}
#' \item{\code{assignment_error_matrix: }}{AEM-matrix containing the conditional
#' probabilities for assigning a unit of category i to categories 1 to n.}
#' }}
#' \item{\code{elements_chance_corrected}}{
#' \itemize{
#' \item{\code{alpha_reliability: }}
#' {A vector containing the chance corrected Alpha Reliabilities for each category.}
#' \item{\code{beta_reliability: }}
#' {A vector containing the chance corrected Beta Reliabilities for each category.}
#' \item{\code{iota: }}
#' {A vector containing the Iota values for each category.}
#' }}
#' }
#' The second component \code{estimates_scale_level} contains elements for
#' describing the quality of the ratings on a scale level. It comprises the
#' following elements:
#' \itemize{
#' \item{\code{avg_iota: }}
#' {Numeric value representing the mean of the Iota values.}
#' \item{\code{min_Iota: }}
#' {Numeric value representing the minimum of the Iota values.}
#' \item{\code{total_iota: }}
#' {Numeric value representing the weighted mean of the Iota values. Class sizes
#' are used for weighting.}
#' \item{\code{aem_index: }}
#' {Numeric value representing the deviation of the AEM from a matrix describing
#' random assignments.}
#' \item{\code{aem_index_weighted: }}
#' {Numeric value representing the deviation of the AEM from a matrix describing
#' random assignments. Categorical sizes are used for weighting. Nominal scale
#' level is assumed.}
#' \item{\code{aem_index_weighted_ord: }}
#' {Numeric value representing the deviation of the AEM from a matrix describing
#' random assignments. Categorical sizes are used for weighting. Ordinal scale
#' level is assumed.}
#' }
#' The third component \code{information} contains important information
#' regarding the parameter estimation. It comprises the following elements:
#'  \itemize{
#' \item{\code{log_likelihood: }}
#' {Log-likelihood of the used solution.}
#' \item{\code{Convergence: }}
#' {If estimation converged 0 else 1.}
#' \item{\code{categorical_sizes: }}
#' {Estimates categorical sizes. This is the estimated amount of the categories.}
#' \item{\code{conformity: }}
#' {\code{0} if the solution is in line with assumptions of weak superiority.
#'  A number greater 0 indicates the number of violations of the assumption
#'  of weak superiority.}.
#' \item{\code{n_condition: }}
#' {\code{TRUE} if the number of observed patterns equals or ist greater than
#' the degrees of freedom. \code{FALSE} if not}.
#' \item{\code{s_condition: }}
#' {\code{TRUE} if the rank of the derivates equals the degrees of freedoms.
#'  \code{FALSE} if not.}
#' \item{\code{deviation: }}
#' {Measure for describing the distance between the different solutions. 0
#' indicates that all solutions generated for the different start values
#' are the same.}
#' \item{\code{n_pattern: }}
#' {Numer of observed patterns.}
#' \item{\code{n_pattern_unordered: }}
#' {Numer of observed patterns if the order of codings are not considered.}
#'  \item{\code{n_parameter: }}
#' {Numer independently estimates parameters.}
#'  \item{\code{random_starts: }}
#' {Numer of random starts for the EM-algorithm.}
#' }
#' @note This is an experimental version of an improved version of the iota
#' concept. Function and results may change in the future. We plan to implement
#' the final version at the beginng of 2023.
#' @export
compute_iota2<-function(data,
                        random_starts=10,
                        max_iterations=5000,
                        cr_rel_change=1e-12,
                        step_size = 1e-4,
                        b_min=.01,
                        trace=TRUE){

  #---------------------------------------------------------------------------
  #Converting input data
  data<-as.data.frame(data)
  categorical_levels<-names(table(data[1]))
  for(i in 2:ncol(data)){
    tmp<-names(table(data[i]))
    for(j in tmp)
      if(j %in% categorical_levels==FALSE){
        categorical_levels<-c(categorical_levels,j)
      }
  }
  categorical_levels<-sort(categorical_levels,decreasing = FALSE)

  for (i in 1:ncol(data)){
    data[[i]]<-factor(x=lapply(data[[i]],as.character),levels=categorical_levels)
  }

  n_rater=ncol(data)
  n_categories<-length(categorical_levels)
  N=nrow(data)

  #-------------------------------------------------------------------------
  #Checking for identification
  n_estimated_parameters<-n_categories*(n_categories-1)+(n_categories-1)
  patterns<-get_patterns(data,categorical_levels)

  #-------------------------------------------------------------------------
  #Performing parameter estimations
  cons_matrix<-matrix(data=FALSE,nrow=n_categories,ncol=n_categories)
  diag(cons_matrix)<-TRUE
  estimates_list<-EM_algo_c(obs_pattern_shape=patterns$shape,
                            obs_pattern_frq=patterns$frq,
                            obs_internal_count=patterns$count,
                            categorical_levels=categorical_levels,
                            step_size = step_size,
                            random_starts=random_starts,
                            max_iterations=max_iterations,
                            rel_convergence=cr_rel_change,
                            trace=trace)

  summary<-matrix(data=NA,nrow=random_starts,ncol=6)
  for(i in 1:random_starts){
    summary[i,1]<-estimates_list[[i]]$log_likelihood
    summary[i,2]<-estimates_list[[i]]$convergence
    summary[i,3]<-i
  }
  #-------------------------------------------------------------------------
  #Sort parameters and check for the number of plausible solutions
  estimates_list_tmp<-estimates_list
  compare_sum<-0
  for(i in 1:length(estimates_list_tmp)){
    #estimates_list_tmp[[i]]<-sort_estimates(estimates_list_tmp[[i]])
    estimates_list_tmp[[i]]["con_violations"]<-check_conformity_c(estimates_list_tmp[[i]]$aem)
    summary[i,4]<-estimates_list_tmp[[i]]$con_violations
    summary[i,5]<-max(estimates_list_tmp[[i]]$categorial_sizes)
    summary[i,6]<-min(estimates_list_tmp[[i]]$categorial_sizes)

    #for(i in 1:(random_starts-1)){
    #  for(j in (i+1):random_starts){
    #    compare_sum<-compare_sum+
    #      sum(abs(estimates_list_tmp[[i]]$aem[,1:(n_categories-1)]-estimates_list_tmp[[j]]$aem[,1:(n_categories-1)]))+
    #      sum(abs(estimates_list_tmp[[i]]$categorial_sizes[1:(n_categories-1)]-estimates_list_tmp[[j]]$categorial_sizes[1:(n_categories-1)]))
    #  }
    #}
    #compare_sum<-compare_sum/((n_categories*(n_categories-1)+(n_categories-1))*choose(random_starts,2))

    #if(i==1){
    #  tmp_compare_matrix<-estimates_list_tmp[[i]]$aem
    #  tmp_compare_cat_sizes<-estimates_list_tmp[[i]]$categorial_sizes
    #} else {
    #  compare_sum<-compare_sum+
    #    sum(abs(
    #      round(tmp_compare_matrix[,1:(n_categories-1)],digits = 3) -
    #        round(estimates_list_tmp[[i]]$aem[,1:(n_categories-1)],digits = 3)
    #    ))+
    #    sum(abs(
    #      round(tmp_compare_cat_sizes[1:(n_categories-1)],digits=3)-
    #        round(estimates_list_tmp[[i]]$categorial_sizes[1:(n_categories-1)],digits=3)))
    #}
    #compare_sum<-compare_sum/(random_starts*
    #                            (n_categories*(n_categories-1)+(n_categories-1)))
  }

  #-------------------------------------------------------------------------
  #Selection of the best estimates
  #Reducing the estimates to parameters that are conform as much as possible
  summary_selected_I<-subset(summary,summary[,6]>b_min)
  if(nrow(summary_selected_I)!=0){
  index_min<-summary_selected_I[match(x=min(summary_selected_I[,1],na.rm = TRUE),
                                      table=summary_selected_I[,1]),3]
  boundaries=FALSE
  } else {
    index_min<-summary[match(x=min(summary[,1],na.rm = TRUE),
                                        table=summary[,1]),3]
  boundaries=TRUE
  }
  #Reducing the estimates to parameters with smallest log_likelihood
  #index_min<-summary_selected_I[match(x=min(summary_selected_I[,1],na.rm = TRUE),
  #                                                       table=summary_selected_I[,1]),3]
  #summary_selected_II<-subset(summary_selected_I,summary_selected_I[,1]==min(summary_selected_I[,1],na.rm = TRUE))
  #Selecting estimates with highest deviation from random guessing in aem
  #summary_selected_III<-subset(summary_selected_II,summary_selected_II[,5]==max(summary_selected_II[,5],na.rm = TRUE))
  #Selecting solution with most equal class sizes
  #index_min<-summary_selected_III[match(x=min(summary_selected_III[,6],na.rm = TRUE),
  #                 table=summary_selected_III[,6]),3]
  estimates<-estimates_list_tmp[[index_min]]
  p_boundaries<-(length(estimates_list_tmp)-nrow(summary_selected_I))/length(estimates_list_tmp)
  #------------------------------------
  #Further computations based on the central estimates

  #Assignment-Error-Matrix
  aem=estimates$aem
  colnames(aem)=categorical_levels
  rownames(aem)=categorical_levels

  #Class Sizes
  p_classes<-estimates$categorial_sizes
  names(p_classes)<-categorical_levels

  #alpha-reliability
  p_alpha_reliability<-as.vector(t(as.matrix(diag(aem))))
  names(p_alpha_reliability)<-categorical_levels
  p_alpha_error<-1-p_alpha_reliability

  #Estimation of beta-error
  p_beta_error<-vector(length = n_categories)
  p_beta_error[]<-1
  names(p_beta_error)<-categorical_levels

  for (k in categorical_levels){
    other_k<-subset(categorical_levels,categorical_levels!=k)
    p_beta_error_condition<-0
    p_beta_error_target<-0
    for(k2 in other_k){
      p_beta_error_condition<-p_beta_error_condition+p_classes[k2]*(1-aem[k2,k2])
      p_beta_error_target<-p_beta_error_target+p_classes[k2]*aem[k2,k]
    }
    if(p_beta_error_condition>0){
      p_beta_error[k]<-p_beta_error_target/p_beta_error_condition
    }
    if(p_beta_error_condition==0){
      p_beta_error[k]<-0
    }
  }
  p_beta_reliability<-1-p_beta_error

  #Estimating normalized and chance corrected alpha values for iota
  alpha<-(p_alpha_reliability-1/n_categories)/(1-1/n_categories)

  #Estimating normalized and chance corrected beta values for iota
  beta<-vector(length = n_categories)
  names(beta)<-categorical_levels
  for (k in categorical_levels){
    other_k<-subset(categorical_levels,categorical_levels!=k)
    p_beta_error_condition_Chance<-0
    p_beta_error_target_chance<-0
    for(k2 in other_k){
      p_beta_error_condition_Chance<-p_beta_error_condition_Chance+p_classes[k2]*(1-1/n_categories)
      p_beta_error_target_chance<-p_beta_error_target_chance+p_classes[k2]*1/n_categories
    }
    tmp<-1-p_beta_error_target_chance/p_beta_error_condition_Chance
    beta[k]<-(p_beta_reliability[k]-tmp)/(1-tmp)
    #beta[k]<-abs((p_beta_reliability[k]-tmp)/(1-tmp))
  }

  #Estimating iota
  beta_error_sum<-vector(length = n_categories)
  for(i in 1:n_categories){
    beta_error_sum[i]<-sum(p_classes*p_alpha_error)-
      p_classes[i]*p_alpha_error[i]
  }
  iota_numerator<-p_classes*p_alpha_reliability
  iota_denominator<-p_classes*p_alpha_reliability+
    p_classes*p_alpha_error+
    p_beta_error*beta_error_sum

  iota<-iota_numerator/iota_denominator
  names(iota)<-categorical_levels

  iota_Total<-p_classes%*%iota
  aem_index<-sum(abs(aem-matrix(data=1/n_categories,nrow = n_categories,ncol=n_categories)))/(2*(n_categories-1))
  aem_index_weighted<-p_classes%*%rowSums(abs(aem-matrix(data=1/n_categories,nrow = n_categories,ncol=n_categories)))/(2*(n_categories-1)/n_categories)

  distance_matrix<-matrix(data=NA,nrow=n_categories,ncol=n_categories)
  for(i in 1:n_categories){
    for(j in 1:n_categories){
      distance_matrix[i,j]<-1-(abs(i-j))/n_categories
    }
  }

  aem_index_weighted_ord<-p_classes%*%rowSums(
    distance_matrix*abs(aem-matrix(data=1/n_categories,nrow = n_categories,ncol=n_categories))/
    (rowSums(distance_matrix)*(n_categories-1)/n_categories))


  #-------------------------------------------------------------------------
  #Summary of all Estimates
  Elements_Chance_Corrected<-NULL
  Elements_Chance_Corrected["alpha_reliability"]<-list(alpha)
  Elements_Chance_Corrected["beta_reliability"]<-list(beta)
  Elements_Chance_Corrected["iota"]<-list(iota)

  Elements_Raw_Estimates<-NULL
  Elements_Raw_Estimates["alpha_reliability"]<-list(p_alpha_reliability)
  Elements_Raw_Estimates["beta_reliability"]<-list(p_beta_reliability)
  Elements_Raw_Estimates["assignment_error_matrix"]<-list(aem)

  Estimates_Categorical_Level<-NULL
  Estimates_Categorical_Level["chance_corrected"]<-list(Elements_Chance_Corrected)
  Estimates_Categorical_Level["raw_estimates"]<-list(Elements_Raw_Estimates)

  Estimates_Scale_Level<-NULL
  Estimates_Scale_Level["average_iota"]<-list(mean(iota))
  Estimates_Scale_Level["min_iota"]<-list(min(iota))
  Estimates_Scale_Level["iota_total"]<-list(iota_Total)
  Estimates_Scale_Level["aem_index"]<-list(aem_index)
  Estimates_Scale_Level["aem_index_weighted"]<-list(aem_index_weighted)
  Estimates_Scale_Level["aem_index_weighted_ord"]<-list(aem_index_weighted_ord)

  Esimtates_Information<-NULL
  Esimtates_Information["log_likelihood"]<-list(estimates$log_likelihood)
  Esimtates_Information["iteration"]<-list(estimates$iteration)
  Esimtates_Information["convergence"]<-list(estimates$convergence)
  Esimtates_Information["p_class_sizes"]<-list(estimates$categorial_sizes)
  Esimtates_Information["conformity"]<-list(estimates$con_violations)
  #Esimtates_Information["n_condition"]<-list(n_condition)
  #Esimtates_Information["s_condition"]<-list(s_condition)
  #Esimtates_Information["deviation"]<-list(compare_sum)
  Esimtates_Information["boundaries"]<-list(boundaries)
  Esimtates_Information["p_boundaries"]<-list(p_boundaries)

  Esimtates_Information["n_pattern"]<-list(patterns$n)
  #Esimtates_Information["n_pattern_unordered"]<-list(patterns_unordered$n_unordered)
  Esimtates_Information["n_parameter"]<-list(n_categories*(n_categories-1)+(n_categories-1))
  Esimtates_Information["random_starts"]<-list(random_starts)
  Esimtates_Information["estimates_list"]<-list(estimates_list_tmp)

  results<-NULL
  results["categorical_level"]<-list(Estimates_Categorical_Level)
  results["scale_level"]<-list(Estimates_Scale_Level)
  results["information"]<-list(Esimtates_Information)

  return(results)
}

